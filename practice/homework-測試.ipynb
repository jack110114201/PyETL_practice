{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import csv\n",
    "import random,time\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists('./104file'):\n",
    "    os.mkdir('./104file')\n",
    "\n",
    "url_A ='https://www.104.com.tw/jobs/search/?ro=0&keyword=%E6%95%B8%E6%93%9A%E5%88%86%E6%9E%90%E5%B8%AB&expansionType=area%2Cspec%2Ccom%2Cjob%2Cwf%2Cwktm&order=1&asc=0&page=1&mode=s'\n",
    "url_B = '&mode=s&jobsource=2018indexpoc'\n",
    "\n",
    "userAgent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'\n",
    "headers = {'User-Agent' : userAgent}\n",
    "    \n",
    "\n",
    "my_params = {'ro':'1', # 限定全職的工作，如果不限定則輸入0\n",
    "             'keyword':'資料科學', # 想要查詢的關鍵字\n",
    "             'area':'6001001000', # 限定在台北的工作\n",
    "             'isnew':'30', # 只要最近一個月有更新的過的職缺\n",
    "             'mode':'l'} # 清單的瀏覽模式\n",
    "    \n",
    "\n",
    "all_job_datas=[]\n",
    "for page in range(1,1+1):\n",
    "    url = url_A+str(page)+url_B\n",
    "    print(url)\n",
    "    htmlFile = requests.get(url,headers=headers,data=my_params)\n",
    "    ObjSoup=bs4.BeautifulSoup(htmlFile.text,'html.parser')\n",
    "    jobs = ObjSoup.find_all('article',class_='js-job-item')                 #搜尋所有職缺  \n",
    "       \n",
    "    for job in jobs:\n",
    "        job_name=job.find('a',class_=\"js-job-link\").text                    #職缺內容\n",
    "        job_company=job.get('data-cust-name')                               #公司名稱\n",
    "        job_loc_ALL=job.find('ul', class_='job-list-intro').findAll('li')\n",
    "        for i in job_loc_ALL:\n",
    "            job_loc = job_loc_ALL[0].text  #地址\n",
    "            work_year = job_loc_ALL[1].text #工作經歷\n",
    "            education = job_loc_ALL[2].text #學歷\n",
    "        job_pay=job.find('span',class_='b-tag--default').text               #薪資\n",
    "        job_url=job.find('a').get('href')[2:]                                   #網址\n",
    "        job_data={'公司名稱':job_company,'職缺內容':job_name,\n",
    "                         '地址':job_loc,'工作經歷':work_year,'學歷':education,'薪資':job_pay,'網址':job_url}\n",
    "        all_job_datas.append(job_data)\n",
    "        print(job_name)\n",
    "        print(job_company)\n",
    "        print(job_loc)\n",
    "        print(work_year)\n",
    "        print(education)\n",
    "        print(job_pay)\n",
    "        print(job_url)\n",
    "        #print(job_data)\n",
    "        print('========================================================')\n",
    "\n",
    "    time.sleep(random.randint(1,3))\n",
    "             \n",
    "fn='104測試.csv'                                             #取CSV檔名\n",
    "columns_name=['公司名稱','職缺內容','地址','工作經歷','學歷','薪資','網址']                     #第一欄的名稱\n",
    "with open(fn,'w',newline='',encoding='utf_8_sig') as csvFile:               #定義CSV的寫入檔,並且每次寫入完會換下一行\n",
    "    dictWriter = csv.DictWriter(csvFile,fieldnames=columns_name)            #定義寫入器\n",
    "    dictWriter.writeheader()       \n",
    "    for data in all_job_datas:\n",
    "        dictWriter.writerow(data)              \n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bafbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./104測試.csv')\n",
    "df.columns = columns_name\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bb9069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"zh-Hant-TW\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "<meta content=\"width=device-width,initial-scale=1.0\" name=\"viewport\"/>\n",
      "<meta content=\"telephone=no\" name=\"format-detection\"/>\n",
      "<title>數據分析師｜歌倫比亞美語顧問_康仕坦實業股份有限公司｜台中市南區－104 人力銀行</title>\n",
      "<meta content=\"【工作內容】台中市南區 - 1.深入了解運營，分析內外部資料，提供分析報告，協同各個部門，執行數據驅動決策\n",
      "2.整理與收集數據，規劃部門運營所需報表\n",
      "3.協助公司數據分析與工具的教育訓練和推廣\n",
      "。薪資：待遇面議（經常性薪資達4萬元或以上）。職務類別：市場調查／市場分析、系統分析師、統計精算人員。休假制度：週休二日。可上班日：不限。工作性質：全職。主動應徵、找工作，請上 104 人力銀行投遞履歷。\" name=\"description\"/>\n",
      "<link href=\"https://www.104.com.tw/job/78bew\" rel=\"canonical\"/>\n",
      "<link href=\"https://m.104.com.tw/job/78bew\" media=\"handheld\" rel=\"alternate\"/>\n",
      "<link href=\"https://m.104.com.tw/job/78bew\" media=\"only screen and (max-width: 640px)\" rel=\"alternate\"/>\n",
      "<link href=\"https://m.104.com.tw/amp/job/78bew\" rel=\"amphtml\"/>\n",
      "<link href=\"android-app://com.m104/m104/job?j=54424b74444e465e393a426b3c463e21958784b30544e46292929296e41463a2d008j52&amp;jobNo=78bew\" rel=\"alternate\"/>\n",
      "<link href=\"ios-app://437817158/m104/job?j=54424b74444e465e393a426b3c463e21958784b30544e46292929296e41463a2d008j52&amp;jobNo=78bew\" rel=\"alternate\"/>\n",
      "<meta content=\"index,follow,noarchive\" name=\"robots\"/>\n",
      "<meta content=\"https://static.104.com.tw/b_profile/cust_picture/2000/16876512000/custintroduce/image1.jpg?v=20210502171654\" name=\"thumbnail\"/>\n",
      "<meta content=\"https://static.104.com.tw/b_profile/cust_picture/2000/16876512000/env/s_962627717424452753.jpg?v=20210502171654\" name=\"thumbnail\"/>\n",
      "<meta content=\"數據分析師｜歌倫比亞美語顧問_康仕坦實業股份有限公司｜台中市南區－104 人力銀行\" property=\"og:title\"/>\n",
      "<meta content=\"【工作內容】台中市南區 - 1.深入了解運營，分析內外部資料，提供分析報告，協同各個部門，執行數據驅動決策\n",
      "2.整理與收集數據，規劃部門運營所需報表\n",
      "3.協助公司數據分析與工具的教育訓練和推廣\n",
      "。薪資：待遇面議（經常性薪資達4萬元或以上）。職務類別：市場調查／市場分析、系統分析師、統計精算人員。休假制度：週休二日。可上班日：不限。工作性質：全職。主動應徵、找工作，請上 104 人力銀行投遞履歷。\" property=\"og:description\"/>\n",
      "<meta content=\"https://www.104.com.tw/job/78bew\" property=\"og:url\"/>\n",
      "<meta content=\"article\" property=\"og:type\"/>\n",
      "<meta content=\"https://static.104.com.tw/b_profile/cust_picture/2000/16876512000/custintroduce/image1.jpg?v=20210502171654\" property=\"og:image\"/>\n",
      "<meta content=\"歌倫比亞美語顧問_康仕坦實業股份有限公司企業形象｜104 人力銀行\" property=\"og:image:alt\"/>\n",
      "<meta content=\"516245975144411\" property=\"fb:app_id\"/>\n",
      "<meta content=\"104 人力銀行\" property=\"og:site_name\"/>\n",
      "<meta content=\"on\" http-equiv=\"x-dns-prefetch-control\"/>\n",
      "<link href=\"https://static.104.com.tw\" rel=\"dns-prefetch\"/>\n",
      "<link href=\"//cdn.104.com.tw\" rel=\"dns-prefetch\"/>\n",
      "<!-- Google Tag Manager -->\n",
      "<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\n",
      "            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\n",
      "            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n",
      "            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n",
      "        })(window,document,'script','dataLayer','GTM-P379T3');</script>\n",
      "<!-- End Google Tag Manager -->\n",
      "<script src=\"https://static.104.com.tw/104i/js/api/log/e104.log.latest.js?v=20190424\"></script>\n",
      "<script src=\"https://static.104.com.tw/104main/libs/mit/jquery/3.3.1/jquery.min.js\"></script>\n",
      "<script src=\"https://static.104.com.tw/104main/libs/mit/jquery-migrate/3.0.1/jquery-migrate.min.js\" type=\"text/javascript\"></script>\n",
      "<script src=\"https://static.104.com.tw/104main/libs/mit/jquery-migrate/1.4.1/jquery-migrate.min.js\" type=\"text/javascript\"></script>\n",
      "<script src=\"https://static.104.com.tw/bubble/js/mainjs.js?by=jbbar&amp;v=20200323\" type=\"text/javascript\"></script>\n",
      "<link href=\"//cdn.104.com.tw/designer-icons/1.1.12/style.css\" rel=\"stylesheet\" type=\"text/css\">\n",
      "<link href=\"//cdn.104.com.tw/cindex/assets/css/chunk-vendors.6215e04d.css\" rel=\"stylesheet\"/>\n",
      "<link href=\"//cdn.104.com.tw/cindex/assets/css/cindex-job.4409ee9b.css\" rel=\"stylesheet\"/>\n",
      "</link></head>\n",
      "<body>\n",
      "<!-- Google Tag Manager (noscript) -->\n",
      "<noscript><iframe height=\"0\" src=\"https://www.googletagmanager.com/ns.html?id=GTM-P379T3\" style=\"display:none;visibility:hidden\" width=\"0\"></iframe></noscript>\n",
      "<!-- End Google Tag Manager (noscript) -->\n",
      "<div id=\"globalbar\">\n",
      "<div id=\"bar_m104\">\n",
      "<div id=\"global_bk\"></div>\n",
      "</div>\n",
      "</div>\n",
      "<noscript>\n",
      "<strong>We're sorry but vue-start doesn't work properly without JavaScript enabled. Please enable it to continue.</strong>\n",
      "</noscript>\n",
      "<div id=\"app\"></div>\n",
      "<script defer=\"\" src=\"https://static.104.com.tw/104main/libs/mit/vue/2.6.12/vue.min.js\"></script>\n",
      "<script defer=\"\" src=\"https://msc.adsmart.104.com.tw/js/channel.js\"></script>\n",
      "<script defer=\"\" src=\"//cdn.104.com.tw/cindex/assets/js/core-js.11a2a895c13795b10d29.js\"></script>\n",
      "<script defer=\"\" src=\"//cdn.104.com.tw/cindex/assets/js/vue.857f299b2d2843024b9e.js\"></script>\n",
      "<script defer=\"\" src=\"//cdn.104.com.tw/cindex/assets/js/popper.js.bd447390f014ce81a0fe.js\"></script>\n",
      "<script defer=\"\" src=\"//cdn.104.com.tw/cindex/assets/js/v-tooltip.3f3583a15f7d35b1ff12.js\"></script>\n",
      "<script defer=\"\" src=\"//cdn.104.com.tw/cindex/assets/js/chunk-vendors.a1b7144dd880552a07c2.js\"></script>\n",
      "<script defer=\"\" src=\"//cdn.104.com.tw/cindex/assets/js/cindex-job.40c4d809a93fb7907ea3.js\"></script>\n",
      "<!-- Start Alexa Certify Javascript -->\n",
      "<script type=\"text/javascript\">\n",
      "        _atrk_opts = { atrk_acct:\"lRlHh1awVK00wf\", domain:\"104.com.tw\",dynamic: true};\n",
      "        (function() { var as = document.createElement('script'); as.type = 'text/javascript'; as.async = true; as.src = \"https://d31qbv1cthcecs.cloudfront.net/atrk.js\"; var s = document.getElementsByTagName('script')[0];s.parentNode.insertBefore(as, s); })();\n",
      "    </script>\n",
      "<noscript><img alt=\"\" height=\"1\" src=\"https://d5nxst8fruw4z.cloudfront.net/atrk.gif?account=lRlHh1awVK00wf\" style=\"display:none\" width=\"1\"/></noscript>\n",
      "<!-- End Alexa Certify Javascript -->\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.104.com.tw/job/78bew?jobsource=jolist_b_relevance\"\n",
    "userAgent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
    "\n",
    "headers = {\n",
    "    \"Referer\": \"https://www.104.com.tw/job/78bew?jobsource=jolist_b_relevance\",\n",
    "    \"User-Agent\" : userAgent\n",
    "}\n",
    "\n",
    "res = requests.get(url = url, headers = headers)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "print(soup)\n",
    "\n",
    "soup.select('div.content > dl > dd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, time, requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 加入使用者資訊(如使用什麼瀏覽器、作業系統...等資訊)模擬真實瀏覽網頁的情況\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'}\n",
    "\n",
    "# 查詢的關鍵字\n",
    "my_params = {'ro':'1', # 限定全職的工作，如果不限定則輸入0\n",
    "             'keyword':'資料科學', # 想要查詢的關鍵字\n",
    "             'area':'6001001000', # 限定在台北的工作\n",
    "             'isnew':'30', # 只要最近一個月有更新的過的職缺\n",
    "             'mode':'l'} # 清單的瀏覽模式\n",
    "\n",
    "url = requests.get('https://www.104.com.tw/jobs/search/?' , my_params, headers = headers).url\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# 網頁的設計方式是滑動到下方時，會自動加載新資料，在這裡透過程式送出Java語法幫我們執行「滑到下方」的動作\n",
    "for i in range(20): \n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(0.6)\n",
    "    \n",
    "# 自動加載只會加載15次，超過之後必須要點選「手動載入」的按鈕才會繼續載入新資料（可能是防止爬蟲）\n",
    "k = 1\n",
    "while k != 0:\n",
    "    try:\n",
    "        # 手動載入新資料之後會出現新的more page，舊的就無法再使用，所以要使用最後一個物件\n",
    "        driver.find_elements_by_class_name(\"js-more-page\",)[-1].click() \n",
    "        # 如果真的找不到，也可以直接找中文!\n",
    "        # driver.find_element_by_xpath(\"//*[contains(text(),'手動載入')]\").click()\n",
    "        print('Click 手動載入，' + '載入第' + str(15 + k) + '頁')\n",
    "        k = k+1\n",
    "        time.sleep(1) # 時間設定太短的話，來不及載入新資料就會跳錯誤\n",
    "    except:\n",
    "        k = 0\n",
    "        print('No more Job')\n",
    "\n",
    "# 透過BeautifulSoup解析資料\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "List = soup.findAll('a',{'class':'js-job-link'})\n",
    "print('共有 ' + str(len(List)) + ' 筆資料')\n",
    "\n",
    "def bind(cate):\n",
    "    k = []\n",
    "    for i in cate:\n",
    "        if len(i.text) > 0:\n",
    "            k.append(i.text)\n",
    "    return str(k)\n",
    "\n",
    "JobList = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "while i < len(List):\n",
    "    # print('正在處理第' + str(i) + '筆，共 ' + str(len(List)) + ' 筆資料')\n",
    "    content = List[i]\n",
    "    # 這裡用Try的原因是，有時候爬太快會遭到系統阻擋導致失敗。因此透過這個方式，當我們遇到錯誤時，會重新再爬一次資料！\n",
    "    try:\n",
    "        resp = requests.get('https://' + content.attrs['href'].strip('//'))\n",
    "        soup2 = BeautifulSoup(resp.text,'html.parser')\n",
    "        df = pd.DataFrame(\n",
    "            data = [{\n",
    "                '公司名稱':soup2.find('a', {'class':'cn'}).text,\n",
    "                '工作職稱':content.attrs['title'],\n",
    "                '工作內容':soup2.find('p').text,\n",
    "                '職務類別':bind(soup2.findAll('dd', {'class':'cate'})[0].findAll('span')),\n",
    "                '工作待遇':soup2.find('dd', {'class':'salary'}).text.split('\\n\\n',2)[0].replace(' ',''),\n",
    "                '工作性質':soup2.select('div > dl > dd')[2].text,\n",
    "                '上班地點':soup2.select('div > dl > dd')[3].text.split('\\n\\n',2)[0].split('\\n',2)[1].replace(' ',''),\n",
    "                '管理責任':soup2.select('div > dl > dd')[4].text,\n",
    "                '出差外派':soup2.select('div > dl > dd')[5].text,\n",
    "                '上班時段':soup2.select('div > dl > dd')[6].text,\n",
    "                '休假制度':soup2.select('div > dl > dd')[7].text,\n",
    "                '可上班日':soup2.select('div > dl > dd')[8].text,\n",
    "                '需求人數':soup2.select('div > dl > dd')[9].text,\n",
    "                '接受身份':soup2.select('div.content > dl > dd')[10].text,\n",
    "                '學歷要求':soup2.select('div.content > dl > dd')[12].text,\n",
    "                '工作經歷':soup2.select('div.content > dl > dd')[11].text,\n",
    "                '語文條件':soup2.select('div.content > dl > dd')[14].text,\n",
    "                '擅長工具':soup2.select('div.content > dl > dd')[15].text,\n",
    "                '工作技能':soup2.select('div.content > dl > dd')[16].text,\n",
    "                '其他條件':soup2.select('div.content > dl > dd')[17].text,\n",
    "                '公司福利':soup2.select('div.content > p')[1].text,\n",
    "                '科系要求':soup2.select('div.content > dl > dd')[13].text,\n",
    "                '聯絡方式':soup2.select('div.content')[3].text.replace('\\n',''),\n",
    "                '連結路徑':'https://' + content.attrs['href'].strip('//')}],\n",
    "            columns = ['公司名稱','工作職稱','工作內容','職務類別','工作待遇','工作性質','上班地點','管理責任','出差外派',\n",
    "                       '上班時段','休假制度','可上班日','需求人數','接受身份','學歷要求','工作經歷','語文條件','擅長工具',\n",
    "                       '工作技能','其他條件','公司福利','科系要求','聯絡方式','連結路徑'])\n",
    "        JobList = JobList.append(df, ignore_index=True)\n",
    "        i += 1\n",
    "        print(\"Success and Crawl Next 目前正在爬第\" + str(i) + \"個職缺資訊\")\n",
    "        time.sleep(0.5) # 執行完休息0.5秒，避免造成對方主機負擔\n",
    "    except:\n",
    "        print(\"Fail and Try Again!\")\n",
    "\n",
    "JobList\n",
    "\n",
    "JobList.to_excel('C:/Users/TLYu0419/Desktop/JobList2.xlsx', encoding='cp950')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
